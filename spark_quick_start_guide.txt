spark quick start guide

#######################################################
# 1. download pkg
#######################################################
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.2-bin-hadoop2.6.tgz

#######################################################
# 2. install spark pkackage
tar xvfz spark-1.5.2-bin-hadoop2.6.tgz 
#######################################################

#######################################################
# 3. download third library
#######################################################
cd lib
wget http://central.maven.org/maven2/com/databricks/spark-csv_2.10/1.3.0/spark-csv_2.10-1.3.0.jar
wget http://central.maven.org/maven2/org/apache/commons/commons-csv/1.2/commons-csv-1.2.jar


#######################################################
#4. set enviornment for python3
#PS. memsql use python3
#######################################################

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/xenv/python/X/3.4.1l_64_RH5/lib
export PATH=$PATH:/xenv/python/X/3.4.1l_64_RH5/bin


#######################################################
#5. prepare start script, run spark in without cluster
# create a script run_local
#######################################################

cat run_local 
#!/bin/bash

export PYSPARK_PYTHON=python3 
export PYSPARK_DRIVER_PYTHON=ipython 


./bin/pyspark \
--driver-class-path  $PWD/lib/spark-csv_2.10-1.3.0.jar:$PWD/lib/commons-csv-1.2.jar \
--jars               $PWD/lib/spark-csv_2.10-1.3.0.jar,$PWD/lib/commons-csv-1.2.jar 

#######################################################
#cat run_standalone, run spark in standalone cluster
#create a script run_standalone
#######################################################

#!/bin/bash

export PYSPARK_PYTHON=python3 
export PYTHONHASHSEED=0
export HADOOP_USER_NAME="bigdatagfts"

./bin/pyspark \
--driver-class-path             $PWD/lib/spark-csv_2.10-1.3.0.jar:$PWD/lib/commons-csv-1.2.jar \
--jars                          $PWD/lib/spark-csv_2.10-1.3.0.jar,$PWD/lib/commons-csv-1.2.jar \
--master                        spark://10.116.37.181:7077

#######################################################
#run a hello word with hadoop
#######################################################

./run_standalone

#input following lines in python spark REPL

from operator import add
lines = sc.textFile('hdfs://10.116.37.181:9000/user/bigdatagfts/README.md')
counts = lines.flatMap(lambda x: x.split(' ') ).map(lambda x: (x, 1) ).reduceByKey(add).sortBy(lambda x: x[1], False) 
output = counts.collect()
for (word, count) in output[:10]:
    print("%-20s: %i" % ('[' + word + ']', count))
    
        